{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Unit 1 - Data Preperation**"
      ],
      "metadata": {
        "id": "yn0imOdANlbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 - Variable Types"
      ],
      "metadata": {
        "id": "iWHuIkNvOXHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "bXozVFX-PYhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8ooCbFM9RKO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preview Data"
      ],
      "metadata": {
        "id": "YF313sexP0W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() #previews the first 5 rows\n",
        "df.head(10) #previews the first 10 rows\n",
        "pd.set_option('display.max_columns', None) #show all columns in the df"
      ],
      "metadata": {
        "id": "0WH-AFSyRN76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Types"
      ],
      "metadata": {
        "id": "ikvN0RfHP0hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() #to ID Python var types\n",
        "\n",
        "int_var = 10\n",
        "float_var = 10.5\n",
        "str_var = 'Hello'\n",
        "bool_var = True"
      ],
      "metadata": {
        "id": "tJT6vBKZRU73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type Conversion"
      ],
      "metadata": {
        "id": "Eip-TqTfP0sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_var = float(int_var)\n",
        "int_var = int(float_var)\n",
        "str_var = str(int_var)\n",
        "bool_var = bool(int_var)"
      ],
      "metadata": {
        "id": "iwRA2RyVRVT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Data To Datetime"
      ],
      "metadata": {
        "id": "O8UH1QjGP04s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['new column name'] = df['new column name'].apply(pd.to_datetime) #create new column and convert to datetime format"
      ],
      "metadata": {
        "id": "rTvWBJAERVsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Operations"
      ],
      "metadata": {
        "id": "lzfk2Zg7P1Ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum_var = int_var + float_var\n",
        "product_var = int_var * float_var\n",
        "diff_var = float_var - int_var\n",
        "div_var = float_var / int_var"
      ],
      "metadata": {
        "id": "Lw2BJbhyRWDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### String Operations"
      ],
      "metadata": {
        "id": "eVkdJr80P1Qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str_concat = str_var + ' World'\n",
        "str_upper = str_var.upper()\n",
        "str_split = str_var.split('e')"
      ],
      "metadata": {
        "id": "-myJmu13RWg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List Operations"
      ],
      "metadata": {
        "id": "S4tocp9WP1b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_var = [1, 2, 3, 4, 5]\n",
        "list_append = list_var.append(6)\n",
        "list_remove = list_var.remove(3)\n",
        "list_slice = list_var[1:4]"
      ],
      "metadata": {
        "id": "VoL8_fgfRXGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dictionary Operations"
      ],
      "metadata": {
        "id": "WcqJjtchP1nQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_var = {'key1': 'value1', 'key2': 'value2'}\n",
        "dict_keys = dict_var.keys()\n",
        "dict_values = dict_var.values()\n",
        "dict_update = dict_var.update({'key3': 'value3'})"
      ],
      "metadata": {
        "id": "-VQL7XOoRXr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Looping and Conditionals"
      ],
      "metadata": {
        "id": "Z-5myU8UP1yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(i)\n",
        "\n",
        "if int_var > 5:\n",
        "    print('Greater than 5')\n",
        "else:\n",
        "    print('Less than or equal to 5')"
      ],
      "metadata": {
        "id": "hL1Th3PgRYBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Visualizations for Qualitative Vars"
      ],
      "metadata": {
        "id": "ODLwmuGeP1-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# below is code to create a bar chart\n",
        "df['column name'].value_counts().plot(kind='bar')\n",
        "plt.title('Chart Title')\n",
        "plt.xlabel('x axis name')\n",
        "plt.ylabel('y axis name')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EphQFPb2RYrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Visualizations for Quantitative Var"
      ],
      "metadata": {
        "id": "Ydb7rEuPP2TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# below is code to create a boxplot\n",
        "df['column name'].plot(kind='box')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YM52Q9SRRZIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Visualizations for Qualitative Continours Var"
      ],
      "metadata": {
        "id": "TBh1etRfRBB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# below is code to create a scatterplot\n",
        "sns.scatterplot(x = df['column name1'], y = df['column name2'])"
      ],
      "metadata": {
        "id": "83IzGpqzRZ_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 - Data Sources"
      ],
      "metadata": {
        "id": "Q--9sz2SOc-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "APJ_w9uoSpcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# add more as needed"
      ],
      "metadata": {
        "id": "7UhTcR_VT7-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read in Datasets of Various File Types"
      ],
      "metadata": {
        "id": "lwJagDfOTByX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df = pd.read_excel('data.xlsx')\n",
        "df = pd.read_json('data.json')\n",
        "df = pd.read_html('https://www.website.com/table')\n",
        "df = pd.read_sql('SELECT * FROM table', connection)"
      ],
      "metadata": {
        "id": "Qamza3EAT8dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Join Two Datasets"
      ],
      "metadata": {
        "id": "qu5XSBirTB_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.merge(specify_df, on='column name', how='left') #specify_df should be the df name"
      ],
      "metadata": {
        "id": "a41Q_FqET82R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter down observations within a Column by searching for specific text strings"
      ],
      "metadata": {
        "id": "3jkwuRkDTCKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['column'].str.contains('string')] # string is contained\n",
        "df = df[df['column'].str.startswith('string')] # string starts with ...\n",
        "df = df[df['column'].str.endswith('string')] # string ends with ...\n",
        "\n",
        "df = df[df['column'].str.contains('string', case=False)] # will ignore upper and lowercasing of words, default is case=True\n",
        "df = df[df['column'].str.startswith('string', case=False)]\n",
        "df = df[df['column'].str.endswith('string', case=False)]"
      ],
      "metadata": {
        "id": "HT080JdMT9JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View counts of each value within a column"
      ],
      "metadata": {
        "id": "zi8YWaskTCTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['column'].value_counts()"
      ],
      "metadata": {
        "id": "8QwO0LNQU0zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View columns within dataframe"
      ],
      "metadata": {
        "id": "QYVazUJeTCda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "A49h-_RmUrtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Created a sorted bar chart in descending order"
      ],
      "metadata": {
        "id": "7IC5kWdsTCno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by='column', ascending=False)\n",
        "df[['bar variable','height variable']].plot(kind='bar', x='bar variable', y='height variable')\n",
        "plt.tile('Title')\n",
        "plt.xlabel('x-axis label')\n",
        "plt.ylabel('y-axis label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PSlId9pNUnXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subset a dataframe to only contain values from a particular column"
      ],
      "metadata": {
        "id": "U5oAFYj_TCz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df[['column'] == 'value']"
      ],
      "metadata": {
        "id": "qaStnlERUlGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Store API Credentials then Set up Request for OpenWeather Map API"
      ],
      "metadata": {
        "id": "RsxybrPsTC_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = 'API_KEY'\n",
        "lat = 'LATITUDE'\n",
        "lon = 'LONGITUDE'\n",
        "url = f'https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}'"
      ],
      "metadata": {
        "id": "CyAWHTibUiAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Request and Return Error if it Doesn't Work"
      ],
      "metadata": {
        "id": "kriUio-wTDLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send a GET request to the API\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Convert the JSON response to a pandas DataFrame\n",
        "    weather_data = response.json()\n",
        "    weather_df = pd.DataFrame([weather_data], columns=weather_data.keys())\n",
        "\n",
        "    # Display the DataFrame\n",
        "    print(weather_df)\n",
        "else:\n",
        "    print(\"Failed to retrieve data: Status code\", response.status_code)"
      ],
      "metadata": {
        "id": "Hj6zc6tKUe1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a bar chart showing the max value for specific dates"
      ],
      "metadata": {
        "id": "WvBQuyOhTDTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['date variable'] = pd.to_datetime(df['date variable']).dt.date\n",
        "df_max = df.groupby('date variable')['column to show max of'].max()\n",
        "\n",
        "df_max.plot(kind='bar')\n",
        "plt.tile('Title')\n",
        "plt.xlabel('x-axis label')\n",
        "plt.ylabel('y-axis label')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "QrMc-_r8Uc9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Data Cleaning"
      ],
      "metadata": {
        "id": "1-hAkDuEOdOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "XkR1D8gRVS1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "0szNDU8RWSwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read in Dataset of Various File Types"
      ],
      "metadata": {
        "id": "4vXjSVPsVWtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df = pd.read_excel('data.xlsx')\n",
        "df = pd.read_json('data.json')"
      ],
      "metadata": {
        "id": "x3nxwGeHWTHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preview First 5 Rows of Dataframe"
      ],
      "metadata": {
        "id": "0d_B_coRVW3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "BniRh4L2WTem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Strip leading or trailing whitespaces from data within columns"
      ],
      "metadata": {
        "id": "pcShkqBkVXBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['column name'] = df['column name'].str.strip() #trims values within a column"
      ],
      "metadata": {
        "id": "mdCW6pHvWT_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.strip() #trims headers only"
      ],
      "metadata": {
        "id": "E_se_ta9XWaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retain only Observations that Are Complete within a Specific Column"
      ],
      "metadata": {
        "id": "0v0OuVJYVXLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_full = df[df['column_name'].notna()]"
      ],
      "metadata": {
        "id": "gM_mFlAgWUUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.isna(df['column_name'])) #check for NaN in a column"
      ],
      "metadata": {
        "id": "uLxhXGDGXQBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examine the Count of Values within a Specific Column"
      ],
      "metadata": {
        "id": "mo0cALhRVXWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['column_name'].value_counts()"
      ],
      "metadata": {
        "id": "ixIRnx-8WUps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replace Values with Other Values"
      ],
      "metadata": {
        "id": "o8onk11wVXgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace(['old value','old value 2', 'old value 3'], ['new value', 'new value 2', 'new value 3']) # list method for multiple values"
      ],
      "metadata": {
        "id": "6BheWMnVWVbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace('old value', 'new value') # list method for one value"
      ],
      "metadata": {
        "id": "gsEQk-ivWzzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace({'old value': 'new value', 'old value 2': 'new value 2', 'old value 3': 'new value 3'}) # dictionary method"
      ],
      "metadata": {
        "id": "Mcb4K9fDWzgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Two New columns by Splitting Text in One Existing Column"
      ],
      "metadata": {
        "id": "KEBvUoNeVXqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify the delimiter then choose from the below\n",
        "df[['column_name_1', 'column_name_2']] = df['column_name'].str.split(' ', 1, expand=True) # space deliminted\n",
        "df[['column_name_1', 'column_name_2']] = df['column_name'].str.split(',', 1, expand=True) # comma deliminted\n",
        "df[['column_name_1', 'column_name_2']] = df['column_name'].str.split(':', 1, expand=True) # colon deliminted\n",
        "df[['column_name_1', 'column_name_2']] = df['column_name'].str.split(';', 1, expand=True) # semicolon deliminted\n",
        "df[['column_name_1', 'column_name_2']] = df['column_name'].str.split('\\t', 1, expand=True) # tab deliminted\n",
        "df[['column_name_1', 'column_name_2']] = df['column_name'].str.split('_', 1, expand=True) # underscore deliminted\n",
        "df[['column_name_1', 'column_name_2']] = df['column_name'].str.split('-', 1, expand=True) # dash deliminted"
      ],
      "metadata": {
        "id": "MJRznD7xWV4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create New Column based on Where Statement from Existing Column"
      ],
      "metadata": {
        "id": "eM-NspS9VX0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['column_name_new'] = np.where(df['column_name'] == 'value', 'value if true', 'value if false')"
      ],
      "metadata": {
        "id": "X7qT37XJWWvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create New Column Based on Multiple Conditions (Nested) from Existing Column"
      ],
      "metadata": {
        "id": "SFFktLRZVX_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conditions = [\n",
        "    (df['column_name'] < 'value'),\n",
        "    (df['column_name'] < 'value 2'),\n",
        "    (df['column_name'] > 'value 3'),\n",
        "] # add more conditions as necessary\n",
        "\n",
        "values = ['value if true', 'value if true 2', 'value if true 3'] # add more values as necessary\n",
        "\n",
        "df['column_name_new'] = np.select(conditions, values) # create new column based on conditions and values"
      ],
      "metadata": {
        "id": "O-SVdrsLWXE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop Column"
      ],
      "metadata": {
        "id": "VVUGUygSVYJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('column name', axis=1)"
      ],
      "metadata": {
        "id": "vxl6-hA-WX_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set and Sort the Index"
      ],
      "metadata": {
        "id": "AFU-jeexVYR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.set_index('column name')\n",
        "df = df.sort_index()"
      ],
      "metadata": {
        "id": "aRlrgJbBWYlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export dataset as Excel file"
      ],
      "metadata": {
        "id": "WqGFnjS6VYaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "df.to_excel('cleaned_dataset.xlsx') #export cleaned data to excel\n",
        "files.download('cleaned_dataset.xlsx') #download cleaned data as Excel file"
      ],
      "metadata": {
        "id": "9CFdxUDSWY-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Unit 2 - Data Understanding**"
      ],
      "metadata": {
        "id": "qpu9RjGYOdpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Descriptive Statistics"
      ],
      "metadata": {
        "id": "nj4YS6duOxGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "N0BSMusSZD0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "QfH62jWmZC-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Dataset"
      ],
      "metadata": {
        "id": "7HJP1dmaZEbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('file.csv')\n",
        "df = pd.read_excel('file.xlsx')"
      ],
      "metadata": {
        "id": "eckbsPjtZCxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataframe Info"
      ],
      "metadata": {
        "id": "PwKaKrNrZgeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df.columns"
      ],
      "metadata": {
        "id": "FRqsNTjDaOG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Variables that should be floats by replacing non-numeric values with NaNs then converting to floats"
      ],
      "metadata": {
        "id": "PEOMKkKrZpbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['column'] = pd.to_numeric(df['column'], errors='coerce')"
      ],
      "metadata": {
        "id": "onUCoG0YaOhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check data type of specific columns"
      ],
      "metadata": {
        "id": "B1AqtRBaZp2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes, df[['Column 1', 'Column 2']].head()"
      ],
      "metadata": {
        "id": "JfFC11bbaO_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Subset of Only Certain Variables of Interest"
      ],
      "metadata": {
        "id": "3zWGZOlnZp91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns # view all columns in df\n",
        "\n",
        "df2 = df[['Column 1', 'Column 2']] # add on as necessary"
      ],
      "metadata": {
        "id": "_vIxt7tdaPV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Distributions of Multiple Variables (Histrogram grid)"
      ],
      "metadata": {
        "id": "EaVD5v98ZqIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna() # drop rows with missing values\n",
        "\n",
        "df.hist(layout = (4,3), figsize=(12,12), bins = 10) # change layout, figsize and bins to match number of histograms required, desired figure size, and number of bars/bins\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k6ptA5SOaQAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display Descriptive Stats & Display Max Columns"
      ],
      "metadata": {
        "id": "ShfSDqPxZqRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None) # show all columns in dataframe\n",
        "\n",
        "df.describe() # show all descriptive stats for each column\n",
        "\n",
        "df.groupby('column').describe() # show descriptive stats for each column grouped by another column\n",
        "\n",
        "df.groupby('grouping column')[['column1 to be described', 'column2 to be described']].describe() # show descriptive stats for one column grouped by another column"
      ],
      "metadata": {
        "id": "rpxtNnq1aQiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display Descriptive Stats of Two Levels of a Group"
      ],
      "metadata": {
        "id": "6NJx-9w9ZqaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Grouping Column')[['Column1 to be grouped', 'Column2 to be grouped']].describe().loc[['Group 1', 'Group 2']]"
      ],
      "metadata": {
        "id": "YQB8wNRMaRAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sort dataframe values of a specific column"
      ],
      "metadata": {
        "id": "MXPA1OGYZqhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(by='column', ascending = False).head() # descending order\n",
        "df.sort_values(by='column', ascending = True).head() # ascending order"
      ],
      "metadata": {
        "id": "7DslXHcNaRTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Color-Mapped Scatterplot to show the relationship between two continous and one categorical variable"
      ],
      "metadata": {
        "id": "XbVAMv_KZqos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6)) # set figure size accordingly\n",
        "\n",
        "scatter = plt.scatter(df['Continous var 1'], df['Continous var 2'], c=df['Contninous var 2'],\n",
        "                      cmap = 'viridis', s = 100) # create scatterplot\n",
        "\n",
        "# add labels for each data point using categorical variable\n",
        "for i, row in df.iterrows():\n",
        "    plt.text(row['Continous var 1'], row['Continous var 2'], row['Categorical var'], fontsize = 10, ha='right')\n",
        "\n",
        "# Add colorbar\n",
        "colorbar = plt.colorbar(scatter)\n",
        "colorbar.set_label('Categorical var')\n",
        "\n",
        "plt.xlabel('Continous var 1')\n",
        "plt.ylabel('Continous var 2')\n",
        "plt.title('Scatterplot with Colorbar')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4r-bgz1VaR-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subset data by searching for specific values within a column"
      ],
      "metadata": {
        "id": "x-G7LOoHaIeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df[df['column'].isin(['value 1', 'value 2'])]"
      ],
      "metadata": {
        "id": "TbyI3NtAaSfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Data Visualizations"
      ],
      "metadata": {
        "id": "0fgO1vSaOxdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "msZx2wBDav8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Czlv_urIbQG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Descriptive Statistics"
      ],
      "metadata": {
        "id": "MNBGoHUTbMBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Column_Name'].describe"
      ],
      "metadata": {
        "id": "V1PnOEzdbTfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate descriptive statistics categorized by group membership"
      ],
      "metadata": {
        "id": "loEW--_PbMMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Column_Name1')['Column_Name2'].describe()\n",
        "\n",
        "#To produce descriptive stats table grouped by a variable, without the ID\n",
        "vars = df.drop(['ID'], axis=1)\n",
        "vars.groupby('DV').describe().stack(0)"
      ],
      "metadata": {
        "id": "YcGGcR9sbav2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Histogram to visualize a data distribution"
      ],
      "metadata": {
        "id": "KOdA4LO3bMQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Column_Name'].hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_qtjlyEpbbHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create histogram and specify number of bins and x-value range"
      ],
      "metadata": {
        "id": "hi5ny3j5bMTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df['Column_Name'], bins = x, range = [y,z]) replace x with number of bins, replace y and z with lower and upper-bounds\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QNGEsGgSbblo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a boxplot visualization"
      ],
      "metadata": {
        "id": "72_mBm1gbMWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(df['Column_Name'])\n",
        "\n",
        "# produce a side by side boxplot of a quant var grouped by a qual var\n",
        "sns.boxplot(x='qual var', y='quant var', data=df)\n",
        "plt.title('title')\n",
        "plt.xlabel('xlabel')\n",
        "plt.ylabel('ylabel')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U5_WUvtvbcDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creat multiple boxplots categorized by group"
      ],
      "metadata": {
        "id": "b9iG-xv2bMZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot(column=['Column_Name1'], by=['Column_Name2'], figsize(x,y))\n",
        "# where column_name1 is your variable on the y-axis, column_name 2 is the grouping variable, and x,y are the width and height dimensions of the figure"
      ],
      "metadata": {
        "id": "P1t4ZuG5bcpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an Aggregation Objects - Counts"
      ],
      "metadata": {
        "id": "9tRFX_PUbMcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_count = df['Column_Name'].value_counts()"
      ],
      "metadata": {
        "id": "gz92YXTpdBvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an Aggregation Objects - Mean\n"
      ],
      "metadata": {
        "id": "-oUVxKbFc_3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category = df['Column_Name'].describe()\n",
        "cagegory_mean = category['mean']\n",
        "average_var = df.groupby('qual var')['quant var'].mean()"
      ],
      "metadata": {
        "id": "SZo5gJc2dFQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an Aggregation Objects - Standard Deviation"
      ],
      "metadata": {
        "id": "LY4C93GtdABJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category = df['Column_Name'].describe()\n",
        "category_std = category['std']"
      ],
      "metadata": {
        "id": "FwFt3ML0dM4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an Aggregation Objects - Group By"
      ],
      "metadata": {
        "id": "9-MUrUNcdAIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "object name = df.groupby(by=\"grouping variable\")[\"variable to be grouped\"].describe()\n",
        "object_mean = object name['mean']"
      ],
      "metadata": {
        "id": "lM2lKzA0dQU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Bar Chart Using Mean"
      ],
      "metadata": {
        "id": "U3FOkRJjbMfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average quant var grouped by a qual var\n",
        "average_var = df.groupby('qual var')['quant var'].mean()\n",
        "\n",
        "# Create the bar chart\n",
        "average_var.plot(kind='bar')\n",
        "plt.title('title')\n",
        "plt.xlabel('xlabel')\n",
        "plt.ylabel('ylabel')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7M4pABSbdaGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Stacked Bar Chart Using Data Aggregate Object"
      ],
      "metadata": {
        "id": "K_sXTowwbMi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x = category_counts.index.values, height = category_counts)\n",
        "plt.show()\n",
        "\n",
        "plt.bar(x = category_average.index.values, height = category_average)\n",
        "plt.show()\n",
        "\n",
        "plt.bar(x = category_sd.index.values, height = category_sd)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QfKekjKbdd9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Scatterplot, Color Coded\n"
      ],
      "metadata": {
        "id": "DU2BHzarbMmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='x var', y='y var', hue='color coded var', data=df)\n",
        "plt.title('title')\n",
        "plt.xlabel('x label')\n",
        "plt.ylabel('y label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aNJs2Aw7dqsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Pie Chart\n"
      ],
      "metadata": {
        "id": "Uoz21euNdkhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(category_count.values, labels = category_count.index.values, autopct = '%1.1f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "78_jEvECdwj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Titles and Axis Labels\n",
        "These can be added on as an additional line of code after you specify the the plot type e.g., plt.pie(x, label)\n"
      ],
      "metadata": {
        "id": "D3qhTfvBdkn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Name of Plot\")\n",
        "\n",
        "plt.ylabel(\"Name of Y-axis\")\n",
        "\n",
        "plt.xlabel(\"Name of X-axis\")\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "nkwf7jyid0om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Outliers + Missing Data"
      ],
      "metadata": {
        "id": "Yi0j3SfEOxkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "qZSp60U3ebBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "pd.set_option('display.max_columns', None) # displays max columns in dataframe"
      ],
      "metadata": {
        "id": "eTB-R8gIelYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read in File as Dataframe"
      ],
      "metadata": {
        "id": "1n1rVRgNed1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df = pd.read_excel('data.xlsx')"
      ],
      "metadata": {
        "id": "-lMl1sC7exX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check for Missing Data"
      ],
      "metadata": {
        "id": "zanoP1hbeelZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "DGZPPdC4e0pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Percent Missing Values for a Var"
      ],
      "metadata": {
        "id": "v8JpCzGQeexW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calcuate percent missing\n",
        "percent_missing = df['var'].isnull().sum() * 100 / len(df['var'])\n",
        "print(f'{percent_missing:.2f}%')"
      ],
      "metadata": {
        "id": "ISnFOjvne2RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate percent missing values for var1 for each var2 category\n",
        "percentage_missing = df.groupby('var2 category')['var1'].apply(lambda x: x.isnull().sum() / len(x) * 100)"
      ],
      "metadata": {
        "id": "wO3ZPDtSe8Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a bar chart to visualize missing data"
      ],
      "metadata": {
        "id": "wrC5Psa7efW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#viz by count\n",
        "missing_data = df.isnull().sum() # count missing values in each column\n",
        "\n",
        "plt.figure(figsize=(10, 6)) # set figure size\n",
        "\n",
        "missing_data[missing_data > 0].plot(kind='bar') # plot missing values\n",
        "\n",
        "plt.title('title') # set title\n",
        "plt.ylabel('Number of Missing Values') # set y-axis label\n",
        "plt.xlabel('Column Name') # set x-axis label\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-KxbpONme2p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#viz by percent missing\n",
        "plt.figure(figsize=(10, 6))\n",
        "percentage_missing.plot(kind='bar')\n",
        "plt.xlabel('x label')\n",
        "plt.ylabel('y label')\n",
        "plt.title('title')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FBP36cSYfHlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Heatmap Visualization to Show Missingness Across Unique IDs"
      ],
      "metadata": {
        "id": "uJ9MJWGEefkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6)) # set figure size\n",
        "\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis') # create heatmap\n",
        "\n",
        "plt.title('title') # set title\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5R4OVkm4e3Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View Columns where data are missing"
      ],
      "metadata": {
        "id": "jhJUImvOefuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Column 1', 'Column 2']][df['Column 1'].isnull()]"
      ],
      "metadata": {
        "id": "ciw5xVXKffhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replace NaNs with other Text/Values"
      ],
      "metadata": {
        "id": "4eq3tmP0ef5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fill in the missing values for a var\n",
        "df['Column 1'].fillna('repalcement text or value', inplace=True)\n",
        "# then check for missing data in that column\n",
        "df['Column 1'].isnull().sum()"
      ],
      "metadata": {
        "id": "jYGbRuERff_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill in missing values with NA for all columns starting with\n",
        "\n",
        "column starts with_cols = [col for col in df.columns if col.startswith('start with text_')]\n",
        "for col in column starts with_cols:\n",
        "  df[col].fillna(\"NA\", inplace=True)\n",
        "\n",
        "df['column name'].isnull().sum()"
      ],
      "metadata": {
        "id": "HVZOxjEmfsFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examine Missingness of one variable against another variable"
      ],
      "metadata": {
        "id": "Fh4mcolMegEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show the value of var1 where var2 is missing\n",
        "df[df['var1'].isnull()][['var1', 'var2']]"
      ],
      "metadata": {
        "id": "sIUMgVsTfgYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a mask that identifies missing values in a column\n",
        "missing_var_mask = df['Column 1'].isnull()\n",
        "\n",
        "#create viz\n",
        "plt.figure(figsize=(10, 6)) # set figure size\n",
        "\n",
        "sns.countplot(data = df, x = 'Column 2', hue = missing_var_mask) # create countplot\n",
        "plt.title('title') # set title\n",
        "plt.xlabel('Column 2') # set x-axis label\n",
        "plt.ylabel('Count') # set y-axis label\n",
        "plt.legend(['Missing', 'Not Missing']) # set legend\n",
        "plt.xticks(rotation=90) # rotate x-axis labels\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "imWdgJSrfzz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examine Outliers in Boxplot"
      ],
      "metadata": {
        "id": "4yMgK0IUegO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Column 1'].plot(kind='box')"
      ],
      "metadata": {
        "id": "Xhn8YDwnfg2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=df['Column 1'])\n",
        "plt.title('title')\n",
        "plt.xlabel('Column 1')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3yfqPZO0f5os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creates a grid of boxplots for int and float variables\n",
        "# Select numerical columns\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Create a grid of boxplots\n",
        "plt.figure(figsize=(20, 15))\n",
        "for i, col in enumerate(numerical_cols):\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  sns.boxplot(x=df[col])\n",
        "  plt.title(col)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JvPfTjbVf5OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Imputation using Mean, Median, Most Frequent (Mode) value"
      ],
      "metadata": {
        "id": "gGOVgkyyegZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create an imputer object that will replace missing values using the mean of the column\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "#creates a copy of the df to avoid modifying the original data\n",
        "dfi = df.copy()\n",
        "\n",
        "#computes the mean of Column 1 and stores it in the imputer\n",
        "imputer.fit(dfi[['Column 1']]) # fit imputer to data\n",
        "\n",
        "#replaces missing values in Column 1 with the computed mean and assigns the result back to the copy dfi\n",
        "dfi['Column 1'] = imputer.transform(dfi[['Column 1']]) # transform data"
      ],
      "metadata": {
        "id": "Z44AQQbIgAjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculates the median of var_lg\n",
        "var_lg = df['var_lg'].median()\n",
        "\n",
        "# Fill the missing values in 'var_lg' with the median\n",
        "dfs = df.copy()\n",
        "dfs['var_lg'].fillna(median_var_lg, inplace=True)\n",
        "\n",
        "# Display missing values after imputation\n",
        "print(\"Missing values after imputation:\")\n",
        "print(dfs['var_lg'].isnull().sum())"
      ],
      "metadata": {
        "id": "cunHZcELgBk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates the mode of a var\n",
        "mode_var = df['var'].mode()[0]\n",
        "\n",
        "# Fill the missing values in 'var' with the mode\n",
        "dfs['var'].fillna(mode_var, inplace=True)\n",
        "\n",
        "# Display missing values after imputation\n",
        "print(\"Missing values after imputation:\")\n",
        "print(dfs['avg_var'].isnull().sum())"
      ],
      "metadata": {
        "id": "HpJM11lHgBW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple Imputation"
      ],
      "metadata": {
        "id": "9lp2v5wEegkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#multivariate imputation to handle missing values\n",
        "dfm = df.copy() # create copy of dataframe\n",
        "\n",
        "features_for_imputation = ['Column 1', 'Column 2'] # list of features to impute\n",
        "\n",
        "iter_imputer = IterativeImputer(max_iter = 10, random_state = 0) # create imputer object\n",
        "dfm[['Column to Impute'] + list(features_for_imputation.columns)] = iter_imputer.fit_transform(dfm[['Column to Impute'] + list(features_for_imputation.columns)]) # fit imputer to data"
      ],
      "metadata": {
        "id": "yvrt_3USgSTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multivariate imputation to handle missing values, leveraging additional features\n",
        "# Display missing values before imputation\n",
        "print(\"Missing values before imputation:\")\n",
        "print(df['var'].isnull().sum())\n",
        "\n",
        "# Create a copy of df\n",
        "dfm = df.copy()\n",
        "\n",
        "# Select columns to use for imputation\n",
        "features_for_imputation = dfm[['Col1', 'Col2', 'Col3']] # student choose their features here\n",
        "\n",
        "# Multiple Imputation using additional features\n",
        "iter_imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "dfm[['var'] + list(features_for_imputation.columns)] = iter_imputer.fit_transform(dfm[['var'] + list(features_for_imputation.columns)])\n",
        "\n",
        "# Display missing values after imputation\n",
        "print(\"Missing values after imputation:\")\n",
        "print(dfm['var'].isnull().sum())"
      ],
      "metadata": {
        "id": "_3A6fklZgVMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View rows that are outliers"
      ],
      "metadata": {
        "id": "AP2LqcUcegvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outliers = df[df['outlier column'] > 'outlier cutoff value'].index.tolist()\n",
        "outliers_df = df.loc[outliers, :]\n",
        "outliers_df"
      ],
      "metadata": {
        "id": "BEdHAvHpga2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform Outliers"
      ],
      "metadata": {
        "id": "t_OWVDoYeg6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['oultier column_lg'] = np.log(df['outlier column'])\n",
        "df['oultier column_sqrt'] = np.sqrt(df['outlier column'])"
      ],
      "metadata": {
        "id": "K8iZEkc-gqj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binning/Discretizing a Continous Variable Column"
      ],
      "metadata": {
        "id": "yuigKnD_ehEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# discretizes a var in dfs by creating the categories\n",
        "\n",
        "# Create a function to categorize the var\n",
        "def categorize_var(var):\n",
        "  if var == 0:\n",
        "    return 0\n",
        "  elif var == 1:\n",
        "    return 1\n",
        "  elif var == 2:\n",
        "    return 2\n",
        "  elif var == 3:\n",
        "    return 3\n",
        "  else:\n",
        "    return '3+'\n",
        "\n",
        "# Apply the function to the 'var' column\n",
        "dfs['var_cat'] = dfs['var'].apply(categorize_var)\n",
        "#check via a bar chart\n",
        "dfs['var_cat'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "Cg8WN02GguDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop Columns"
      ],
      "metadata": {
        "id": "DhpEjXUsehQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['column to drop'], axis=1, inplace=True)\n",
        "df.drop(['column to drop 1', 'column to drop 2'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "YqvHfsRjg0BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write Dataframe to CSV"
      ],
      "metadata": {
        "id": "1WOGq0zAehZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('file name.csv', index=False)"
      ],
      "metadata": {
        "id": "1DF8I3qXayRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Unit 3 - Data Modeling**"
      ],
      "metadata": {
        "id": "TpKS3H5VO1HS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 - Correlation Analysis and T-Tests"
      ],
      "metadata": {
        "id": "3pUCeF0GPTBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries\n"
      ],
      "metadata": {
        "id": "WxxYsutfh76P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import ttest_ind, pearsonr, spearmanr, ttest_1samp, ttest_rel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "\n",
        "#If checking for ouliers add below\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer"
      ],
      "metadata": {
        "id": "18QMlAPHiKmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Produce Descriptive Stats, Dropping out Unnecessary Columns\n"
      ],
      "metadata": {
        "id": "Fgek42GDiIhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Column 1', 'Column 2'], axis = 1).describe()\n",
        "df_corr = df.drop(columns=['var1', 'var2', 'var3']) #drop without describing and assigning to df_corr"
      ],
      "metadata": {
        "id": "KTEPM1b0iOv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Produce Histogram Grid\n"
      ],
      "metadata": {
        "id": "UhLQ07J9iI1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(layout = (2, 2), figsize = (10, 10), bins = 10) # adjust parameters as necessary\n",
        "plt.show()\n",
        "\n",
        "df_corr.hist(layout=(6,6), figsize=(16,24), bins=15 #generate histos for vars assigned to df_corr\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cGdouqLdiSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create df to store transformed vars\n"
      ],
      "metadata": {
        "id": "Ba6Xi3UriJAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_corrT = pd.DataFrame()"
      ],
      "metadata": {
        "id": "U7n9BGbliTxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log or Square Root Transform Variables\n"
      ],
      "metadata": {
        "id": "7LkwNbSOiJKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Column 1_sqrt'] = np.sqrt(df['Column 1'])\n",
        "df['Column 2_log'] = np.log(df['Column 2'])\n",
        "\n",
        "#add originally normally distributed var to df_corrT\n",
        "df_corrT['var'] = df['var']"
      ],
      "metadata": {
        "id": "RZE5umDCiZ7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Produce heat-mapped correlation matrix\n"
      ],
      "metadata": {
        "id": "vKRZPnLxiJUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pearson's\n",
        "cor_matrix = df.corr()\n",
        "cor_matrix.style.background_gradient(cmap = 'seismic', axis = None, vmin = -1, vmax = 1)\n",
        "\n",
        "#Spearman's\n",
        "cor_matrix = df_corrT.corr(method = 'spearman') #creates correlation matrix\n",
        "cor_matrix.style.background_gradient(cmap='seismic', axis=None, vmin=-1, vmax=1) #formatting matrix"
      ],
      "metadata": {
        "id": "VIsGSqGYiaNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Produce Scatterplot between 2 variables\n"
      ],
      "metadata": {
        "id": "sFJJZj6EiJeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df['Column 1'], df['Column 2'])\n",
        "plt.xlabel('Column 1')\n",
        "plt.ylabel('Column 2')\n",
        "plt.title('Scatterplot Title')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-ZXuEeplinMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate the Correlation Coefficient, test statistical significance of relationship\n"
      ],
      "metadata": {
        "id": "sHCb0aZfiJnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pearson's\n",
        "corr, p_value = pearsonr(df['Column 1'], df['Column 2'])\n",
        "\n",
        "print('Pearson Correlation Coefficient:', corr)\n",
        "print('p-value:', p_value)\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print('There is a significant correlation between Column 1 and Column 2.')\n",
        "else:\n",
        "    print('There is no significant correlation between Column 1 and Column 2.')\n",
        "\n",
        "#Spearman's\n",
        "corr, p_value = spearmanr(df_corrT['Column 1'], df_corrT['Column 2'])\n",
        "\n",
        "# Print the results\n",
        "print('Spearman correlation coefficient:', corr)\n",
        "print('P-value:', p_value)"
      ],
      "metadata": {
        "id": "oz9fLBdNinpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Spearman Rho Correlation Analysis on Particular Variables\n"
      ],
      "metadata": {
        "id": "DaZocG37iJwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cor_matrix2 = df[['Var 1', 'Var 2', 'Var 3']].corr(method = 'spearman')\n",
        "cor_matrix2.style.background_gradient(cmap = 'seismic', axis = None, vmin = -1, vmax = 1)"
      ],
      "metadata": {
        "id": "R_Ac1gN0ioH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregate Converging Variables\n"
      ],
      "metadata": {
        "id": "70GGfybeiJ5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Aggregated_Var'] = df[['Var 1', 'Var 2']].mean(axis = 1)\n",
        "df.drop(['Var 1', 'Var 2'], axis = 1, inplace = True) # remove non-aggregated versions of vars from dataframe"
      ],
      "metadata": {
        "id": "p8OoSduEiohr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two Sample Independent T-Test\n"
      ],
      "metadata": {
        "id": "hvbMkEoSiKAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_1 = df[df['Group'] == 'Group 1']\n",
        "group_2 = df[df['Group'] == 'Group 2']\n",
        "\n",
        "t_stat, p_value = ttest_ind(group_1['Var 1'], group_2['Var 1'])\n",
        "\n",
        "print('t-statistic:', t_stat)\n",
        "print('p-value:', p_value)"
      ],
      "metadata": {
        "id": "m9mvlnFvio5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paired T-Test\n"
      ],
      "metadata": {
        "id": "ucPpLqOziKG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_stat, p_value = ttest_rel(df['Time 1'], df['Time 2'])\n",
        "\n",
        "print('t-statistic:', t_stat)\n",
        "print('p-value:', p_value)"
      ],
      "metadata": {
        "id": "YX03tcH0ipd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 - Association Rules Analysis"
      ],
      "metadata": {
        "id": "b0sEXeu-hqnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "qTM-vNwyjL8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules"
      ],
      "metadata": {
        "id": "XkU9VitXje0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set ID as Index"
      ],
      "metadata": {
        "id": "2FdXyeTZjbmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ar = df_ar.set_index('id') # set id as your index\n",
        "df_ar.head()"
      ],
      "metadata": {
        "id": "MR4aW-I0jhLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert transactional data to dummy variables"
      ],
      "metadata": {
        "id": "gseZ1D86jbwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(df[\"Column_Name\"].apply(lambda X:x.split(\",\"))) #splits values within `Column_Name` to a list, based on \",\"\n",
        "\n",
        "from mlxtend.preprocessing import TransactionEncoder #import transactionencoder function from mlxtend\n",
        "a = TranactionEncoder() #save function in object called 'a'\n",
        "a_data = a.fit(data).transform(data) #create new data object that transforms list to dummy variables for each item\n",
        "df = pd.DataFrame(a_data,columns=a.columns_) #create new dataframe object from the dummy variables, take column names\n",
        "df"
      ],
      "metadata": {
        "id": "FMCfLkwpjhb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replace True/False Values with 1 and 0s using dictionary"
      ],
      "metadata": {
        "id": "DZoiIfXWjb47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace({True: 1, False: 0}, inplace=True)"
      ],
      "metadata": {
        "id": "rvSyCbSpjiBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If any columns are duplicated, make sure to trim whitespace then drop duplicated columns"
      ],
      "metadata": {
        "id": "eKDSO1uQjcCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.replace(' ', '') #trim leading and trailing whitespace from column names\n",
        "df = df.loc[:, ~df.columns.duplicated()] #drop duplicated columns"
      ],
      "metadata": {
        "id": "-WLaGamrjia9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Apriori Function to Generate Frequent Rulesets"
      ],
      "metadata": {
        "id": "5oX15lydjcNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_is = apriori(df, min_support = 0.2, use_colnames = True) #change the minimum support value\n",
        "freq_is #show the frequent itemsets table"
      ],
      "metadata": {
        "id": "iGklOMCyjise"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Association Rules Analysis"
      ],
      "metadata": {
        "id": "5f2_fSuMjcW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ar = association_rules(freq_is, metric = \"confidence\", min_threshold = 0.6) #change minimum_threshold confidence value\n",
        "df_ar\n",
        "\n",
        "ar_table = association_rules(freq_is, metric = \"confidence\", min_threshold = 0.6) #change minimum_threshold confidence value\n",
        "ar_table"
      ],
      "metadata": {
        "id": "gOgBIEJXjjBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate support count, support, confidence and lift by formula"
      ],
      "metadata": {
        "id": "b5iRzAqAjcfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = df['Column_name'].sum() #calculate support count of itemset containing one item\n",
        "sc = len(df[(df['Col_1'] == 1) &  (df['Col_3'] == 1)]) #calculate support count of itemset containing 2 items\n",
        "\n",
        "support = sc/len(df) #divide the support count by the total number of observations in df"
      ],
      "metadata": {
        "id": "Yv4YILUSkIsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc_x = len(df[(df['Col_1'] == 1) & (df['Col_2'] == 1)]) #support count of antecedent with two items in itemset\n",
        "sc_xy = len(df[(df['Col_1'] == 1) & (df['Col_2'] == 1) & df['Col_3'] == 1]) #support count of antecendent and consequent\n",
        "\n",
        "confidence = sc_xy/sc_x #divide support count of antecendent and consequent by the support count of the antecedent"
      ],
      "metadata": {
        "id": "3UoMEAREkJLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc_y = df['Col_1'].sum() #support count of consequent with itemset with one item\n",
        "s_y = sc_y/len(df) #support of consequent\n",
        "\n",
        "sc_x = len(df[(df['Col_2'] == 1) & (df['Col_3'] == 1)]) #support count of antecedent with two items\n",
        "sc_xy = len(df[(df['Col_2'] == 1) & (df['Col_3'] == 1) & (df['Col_3'] == 1)]) #calculate support count of ante/cons\n",
        "\n",
        "confidence = sc_xy/sc_x #confidence of x --> y\n",
        "Lift = confidence/s_y #lift of x --> y"
      ],
      "metadata": {
        "id": "52odqwDjjjb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 - Clustering Analysis"
      ],
      "metadata": {
        "id": "IRTKf0ihPTPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "4ARAqWcmksLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kneed # installs the kneed library\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from kneed import KneeLocator\n",
        "import sklearn.cluster\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "1tSQoxUzljWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select Specific columns and Store as Separate dataframe"
      ],
      "metadata": {
        "id": "1ggvbd2NlDqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to list attributes you want included\n",
        "features = df[['col1', 'col2', 'add as necessary']]\n",
        "\n",
        "# to list attributes you want dropped\n",
        "features = df.copy()\n",
        "features = features.drop(['col1', 'col2', 'add as necessary'], axis=1)\n",
        "features.head()\n",
        "\n",
        "# to further subset\n",
        "features = features[['col1', 'col2', 'add as necessary']]\n",
        "features.head()"
      ],
      "metadata": {
        "id": "OedUcPfXlk_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dummy Code any Categorical Variables"
      ],
      "metadata": {
        "id": "2JJUHki2lD9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = pd.get_dummies(data = features, dtype = 'int')\n",
        "# or\n",
        "features = pd.get_dummies(features)"
      ],
      "metadata": {
        "id": "hdDwcEw2llYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop Missing"
      ],
      "metadata": {
        "id": "n6DuvWeYlEJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = features.dropna(subset=['col to drop na'])"
      ],
      "metadata": {
        "id": "hksArY1BlmED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scale All Variables in Features"
      ],
      "metadata": {
        "id": "j-cIHW5BlETs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "scaled_features"
      ],
      "metadata": {
        "id": "R27exEx8lmhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize KMeans_kwargs Dictionary"
      ],
      "metadata": {
        "id": "5JphIp41lEfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_kwargs = {\n",
        "    \"init\": \"random\",\n",
        "    \"n_init\": 10,\n",
        "    \"max_iter\": 300,\n",
        "    \"random_state\": 42,\n",
        "}"
      ],
      "metadata": {
        "id": "lbLz-T7Blm-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run KMeans ForLoop for Range of K (x,y)\n"
      ],
      "metadata": {
        "id": "OR7Qz9l5lErO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sse = [] #create empty list for SSE values\n",
        "for k in range(x, y):\n",
        "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
        "    kmeans.fit(scaled_features)\n",
        "    sse.append(kmeans.inertia_)"
      ],
      "metadata": {
        "id": "jwxkLRvKlnWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Elbow Plot of Clusters to Inertia Values"
      ],
      "metadata": {
        "id": "NEM1FnSnlE1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"fivethirtyeight\")\n",
        "plt.plot(range(x, y), sse)\n",
        "plt.xticks(range(x, y))\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2i8I34ImlnuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Locate Knee in Plot"
      ],
      "metadata": {
        "id": "JWc21E7SlE_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kl = KneeLocator(range(x, y), sse, curve=\"convex\", direction=\"decreasing\")\n",
        "kl.elbow"
      ],
      "metadata": {
        "id": "nLGC7HHeloOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run KMeans Parameters Including Number of Clusters"
      ],
      "metadata": {
        "id": "kg_gacnplFJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters = K,\n",
        "                init = 'random',\n",
        "                max_iter = 300,\n",
        "                n_init = 10,\n",
        "                random_state = 42) # change parameters as necessary"
      ],
      "metadata": {
        "id": "Pny_r8jelo0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit KMeans to Data, Examine Inertia Value"
      ],
      "metadata": {
        "id": "qw5OgiK9lFTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.fit(scaled_features)\n",
        "kmeans.inertia_"
      ],
      "metadata": {
        "id": "th6zkhtalpLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Clusters with 2D TSNE plot"
      ],
      "metadata": {
        "id": "M1E7XHx_lFdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TSNE(n_components = 2, random_state = 42) # change parameters as necessary\n",
        "\n",
        "transformed_data = model.fit_transform(scaled_features) # fit and transform the data\n",
        "cluster_labels = kmeans.labels_ # get the cluster labels\n",
        "\n",
        "plt.figure(figsize = (10, 8)) # set the figure size\n",
        "sns.scatterplot(x = transformed_data[:, 0], y = transformed_data[:, 1], hue = cluster_labels) # plot the data with cluster labels\n",
        "\n",
        "plt.title('Title') # set the title\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.legend(title='Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zm35l6RclpgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Produce Centroid Table (Scaled)"
      ],
      "metadata": {
        "id": "p7l6sMWDlFn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "centroids = kmeans.cluster_centers_\n",
        "centroids_table = pd.DataFrame(centroids, columns = features.columns, index = range(kmeans.n_clusters))\n",
        "centroids_table"
      ],
      "metadata": {
        "id": "r1_-EcG3lp2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Produce Centroid Table (Unscaled)"
      ],
      "metadata": {
        "id": "yTvOuLh_lFxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unscaled = scaler.inverse_transform(centroids)\n",
        "unscaled_table = pd.DataFrame(unscaled, columns = features.columns, index = range(kmeans.n_clusters))\n",
        "unscaled_table"
      ],
      "metadata": {
        "id": "XxkjpJ5LlqPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Centroids for Set Features"
      ],
      "metadata": {
        "id": "Kpbw8QY2lF6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIw2mQ5MNdpC"
      },
      "outputs": [],
      "source": [
        "centroids_table.plot(kind = 'line', y = ['col 1', 'col 2', 'col 3']) # scaled line chart\n",
        "plt.title('Title')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Value')\n",
        "plt.show()\n",
        "\n",
        "unscaled_table.plot(kind = 'bar', y = ['col 1', 'col 2', 'col 3']) # unscaled bar chart\n",
        "plt.title('Title')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Value')\n",
        "plt.show"
      ]
    }
  ]
}