{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ICE: Sources of Data\n",
        "## Name:\n",
        "## *DATA 3300*\n",
        "\n",
        "In this in-class exercise we will examine different ways that we can source data, beginning with precompiled datasets, followed by web APIs, and then finally we will produce our own dataset from a class survey."
      ],
      "metadata": {
        "id": "Sd5-WFo3rqiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever I am working on putting together a dataset, I do so with the intention of solving a particular problem or answering a particular question. This will guide what data I need to source!\n",
        "\n",
        "**So, let's say we're starting a Travel Agency business to help individuals plan optimal trips to National Parks, what sort of data might we want to make data-driven recommendations?**"
      ],
      "metadata": {
        "id": "VzLh2EgCrAHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   \n",
        "*   \n",
        "\n"
      ],
      "metadata": {
        "id": "CU8Pat_zrtnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part A) Primary Data Collection**\n",
        "\n",
        "Surveys are one common way of collecting data, and it can be a helpful way for gathering information from specific individuals. Let's [create a survey](https://docs.google.com/forms/u/0/) with five or so questions we think will help us plan a National Parks Holiday trip!\n",
        "\n",
        "These questions should help us narrow down their preferences around:\n",
        "\n",
        "\n",
        "\n",
        "*   Region of the country to visit\n",
        "*   Preference around traffic\n",
        "*   Type of sites preferred\n",
        "*   Trail activity type preference\n",
        "*   Weather preferences\n",
        "\n"
      ],
      "metadata": {
        "id": "YxvQIKh15r9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "zDspybiYEPHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.read_csv ('insert file path') # import sheets data\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "h4uEQurQ6pYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Part B) Secondary Data Collection**\n",
        "\n",
        "Let's begin with examining some sources of precompiled datasets. Websites I often use for sourcing datasets include:\n",
        "\n",
        "*   Government websites, like [Transparent Utah](https://transparent.utah.gov/job_title_search.php)\n",
        "*   [Kaggle](https://www.kaggle.com/datasets)\n",
        "*   [Data is Plural](https://www.data-is-plural.com/archive/)\n",
        "\n",
        "Let's see what precompiled data is out there that might be useful related to finding info on national parks!"
      ],
      "metadata": {
        "id": "EqRLsiPnnNQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[National Parks Dataset](https://www.kaggle.com/datasets/thedevastator/the-united-states-national-parks?select=df_2.csv)\n",
        "\n",
        "[National Park Trails](https://www.data-is-plural.com/archive/2020-08-26-edition/)"
      ],
      "metadata": {
        "id": "jiU9e6VPusL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parks = pd.read_csv('') # load in data set\n",
        "parks.head()"
      ],
      "metadata": {
        "id": "ih2dW5ncurqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Narrow Down the Dataset: Let's filter down this dataset some to parks of interest based on their Location -- Assume we want to stick to locations in the Intermountain West. How can we use the Location columns to narrow down our list?**"
      ],
      "metadata": {
        "id": "7LPaIYJi0LKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QVLHMDPe3mI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_parks = parks[parks['Location'].str.startswith(())] # add in strings to filter down location\n",
        "filtered_parks.head()"
      ],
      "metadata": {
        "id": "XZnHMkukza5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the parks within those locations"
      ],
      "metadata": {
        "id": "nXJDUHuaz5fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) If we know our customer is interested in specific geographic sites or types of sites, how can we further filter down parks?**"
      ],
      "metadata": {
        "id": "5Dhcb18k0JTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hulPF0-234IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mountain_parks = filtered_parks[filtered_parks['Description'].str.contains()] # add in description, why are we using contains here instead of startsiwth?\n",
        "mountain_parks.head()"
      ],
      "metadata": {
        "id": "UirilB6m0dqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mountain_parks['Name'].value_counts() # check the parks count"
      ],
      "metadata": {
        "id": "GCGgCdci0rSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Now let's Incorporate our Trail Data! What pieces of information tie together these two datasets?**"
      ],
      "metadata": {
        "id": "SMrHhyCj5R4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trails = pd.read_csv() # read in second dataset\n",
        "trails.head()"
      ],
      "metadata": {
        "id": "yvssAvKUvZAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7Umhm2HLsLHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Join the datasets by mapping Name to Unitcode then joining on the same primary key!**"
      ],
      "metadata": {
        "id": "GAmCyysBsXCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parks_nps_codes = {\n",
        "    \"Glacier\": \"\",\n",
        "    \"Grand Teton\": \"\",\n",
        "    \"Great Sand Dunes\": \"\",\n",
        "    \"Rocky Mountain\": \"ROMO\",\n",
        "    \"Saguaro\": \"SAGU\",\n",
        "    \"Yellowstone\": \"YELL\"\n",
        "}\n",
        "\n",
        "# Rename the 'Name' column to 'UNITCODE' and replace values using parks_nps_codes\n",
        "mountain_parks = mountain_parks.rename() # fill in rename argument\n",
        "mountain_parks['UNITCODE'] = mountain_parks['UNITCODE'].replace() # fill in replace argument\n",
        "mountain_parks.head()"
      ],
      "metadata": {
        "id": "gQNkNxobp8AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = # create new dataframe by merging mountain_parks and trails\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "m_28T25crKK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view all columns in merged_df"
      ],
      "metadata": {
        "id": "9JU-1Y3PzFbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) What has changed about the structure of the dataset? (Apart from adding new columns from the join)?**"
      ],
      "metadata": {
        "id": "iAIOHJkPsnUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9I6a3injsvDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part C) OpenWeatherMaps API - Let's Check the Forecast at our Parks of Interest!**"
      ],
      "metadata": {
        "id": "eySNy62N2jeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access the OpenWeatherMap API, first navigate [here](https://openweathermap.org/api) and sign up for an account!\n",
        "\n",
        "Then we will navigate to the `My API Keys` page under your profile, to generate an API key. This is all we need (aprt from the request/endpoint) to start pulling data from this website!"
      ],
      "metadata": {
        "id": "9Z-pKT7xkS40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Store API Credentials**\n",
        "\n",
        "Note: This isn't a great way to do this. But since this is a free account we're not too worried about security."
      ],
      "metadata": {
        "id": "XFoMZRFSk_U-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API Key (replace 'your_api_key' with the actual API key)\n",
        "api_key = '' #9c9681d1ee3a680fd15053968fa4c0a5'"
      ],
      "metadata": {
        "id": "eup-An3NlGaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Set up your request!**\n",
        "\n",
        "Here, the goal is to add the average temperature for each of our six parks into our dataset, using the Openweather maps API."
      ],
      "metadata": {
        "id": "WnLTYNq2lJ_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parks_info = {\n",
        "    \"GLAC\": {\"lat\": 48.6966, \"lon\": -113.7183},\n",
        "    \"GRTE\": {\"lat\": 43.7904, \"lon\": -110.6818},\n",
        "    \"GRSA\": {\"lat\": 37.7926, \"lon\": -105.5943},\n",
        "    \"ROMO\": {\"lat\": 40.3428, \"lon\": -105.6836},\n",
        "    \"SAGU\": {\"lat\": 32.2967, \"lon\": -111.1666},\n",
        "    \"YELL\": {\"lat\": 44.4280, \"lon\": -110.5885}\n",
        "} # add comment"
      ],
      "metadata": {
        "id": "UgNcU-pjulMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add comments\n",
        "avg_temp_summary = []\n",
        "\n",
        "#\n",
        "for unit_code, coords in parks_info.items():\n",
        "    lat, lon = coords['lat'], coords['lon']\n",
        "\n",
        "    #\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={api_key}&units=imperial\"\n",
        "\n",
        "    #\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON response\n",
        "        forecast_data = response.json()\n",
        "        forecast_list = forecast_data['list']\n",
        "\n",
        "        #\n",
        "        df_forecast = pd.DataFrame([{\n",
        "            'datetime': item['dt_txt'],\n",
        "            'temperature': item['main']['temp']\n",
        "        } for item in forecast_list])\n",
        "\n",
        "        #\n",
        "        df_forecast['datetime'] = pd.to_datetime(df_forecast['datetime'])\n",
        "\n",
        "        #\n",
        "        df_forecast['date'] = df_forecast['datetime'].dt.date\n",
        "        daily_avg_temps = df_forecast.groupby('date')['temperature'].mean().reset_index()\n",
        "\n",
        "        #\n",
        "        five_day_avg_temp = daily_avg_temps['temperature'].mean()\n",
        "\n",
        "        #\n",
        "        avg_temp_summary.append({'UNITCODE': unit_code, 'five_day_avg_temp': five_day_avg_temp})\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data for {unit_code}: Status code\", response.status_code)\n",
        "\n",
        "\n",
        "df_avg_temp_summary = # Create a DataFrame from the summary list\n",
        "\n",
        "\n",
        "merged_df = merged_df.merge() # Merge the summary DataFrame with your existing merged_df on UNITCODE\n",
        "\n",
        "\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "sCdRYP2Uur86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Why are the values in five_day_avg_temp repeated?**"
      ],
      "metadata": {
        "id": "74ZPXa_zylSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8kvZxf5OyrV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) What is the difference between an inner (what we did the first time) and left merge (what we just did)?**"
      ],
      "metadata": {
        "id": "FXBwRtUR3f3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6K2Lbnpq3mO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part D) Build a Park \\& Trail Recommender!**"
      ],
      "metadata": {
        "id": "7BAd3BYk4K9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def park_recommender(activity, state, n=5, popular=True):\n",
        "    # Add comments\n",
        "    state_parks = merged_df[merged_df['Location'].str.startswith(state, na=False)]\n",
        "\n",
        "    #\n",
        "    activity_parks = state_parks[state_parks['TRLUSE'].str.contains(activity, case=False, na=False)]\n",
        "\n",
        "    #\n",
        "    activity_parks = activity_parks.sort_values(\n",
        "        'Recreation visitors (2021)[11]',\n",
        "        ascending=not popular\n",
        "    )\n",
        "\n",
        "    #\n",
        "    top_parks = activity_parks.head(n)\n",
        "\n",
        "    return top_parks[['UNITCODE', 'Location', 'add whatever columns you want displayed for the top trails/parks']]"
      ],
      "metadata": {
        "id": "A8gY3uQiy8JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations = park_recommender(\"activity\", \"state\", n=10)\n",
        "recommendations"
      ],
      "metadata": {
        "id": "o2yNpp4x2th3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Describe how the recommender works -- why have these particular trails been recommended?**"
      ],
      "metadata": {
        "id": "XWUTWjqi6uIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P3Qvjmxf60R5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Does this recommender suit the needs of our client (based on the data we wanted to collect from them)? Explain.**"
      ],
      "metadata": {
        "id": "joG8X1Zx8XA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CPdqABpw8ja8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) How can we improve our approach? Should we be asking different questions in our survey? Trying to source different data? Trying to change our recommender function?**"
      ],
      "metadata": {
        "id": "bwCUVGgY60r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FC4zbId07DLI"
      }
    }
  ]
}